---
title: "Homework 6"
author: "Siyan Wen"
date: "2023-11-30"
output: html_document
---

```{r}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)
```
# Problem 2
#### Download the data.
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```
#### Bootstrap and SLR 
```{r}
bootstrap_result_glance=
  weather_df|>
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin +prcp , data = df)),
    results = map(models, broom::glance)) |> 
  select(results) |> 
  unnest(results)
  

bootstrap_result_tidy=
  weather_df|>
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin +prcp , data = df)),
    results = map(models, broom::tidy)) |> 
  select(results) |> 
  unnest(results)|>
  select(term,estimate)|>
  pivot_wider(
    names_from=term,
    values_from=estimate
  )|>
  unnest()

```
#### Show distribution
```{r}
r.squared_distribution=
  bootstrap_result_glance|>
  ggplot(aes(x = r.squared)) + geom_density()
print(r.squared_distribution)

log_distribution=
  bootstrap_result_tidy|>
  mutate(log.value=log10(tmin*prcp))|>
  ggplot(aes(x = log.value)) + geom_density()

print(log_distribution)
```

**Description:**

The distribution of "r.squared" exhibits a notable heavy tail extending to low values. Additionally, there is a slight bump in the distribution, possibly the features mentioned above indicating occasional occurrences of larger outliers within the bootstrap samples. 

The distribution of "log" exhibits a even more notable heavy tail extending to the low values. This is an uni-modal and left/negative skewed distribution. This shows a tendency for the majority of values to cluster on the right side, with a tail extending towards the lower values.

#### Confidence interval
```{r}
bootstrap_result_glance |> 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))

bootstrap_result_tidy|>
  mutate(log.value=log10(tmin*prcp))|>
  summarize(
    ci_lower_log.value = quantile(log.value, 0.025,na.rm = TRUE), 
    ci_upper_log.value = quantile(log.value, 0.975,na.rm = TRUE)
    )
```
# Problem 3

#### Load and clean the data
```{r}
birthweight=
  read_csv("data/birthweight.csv")|>
  janitor::clean_names()|>
  select(bwt,blength,gaweeks,bhead,babysex,mrace)|>
  mutate(babysex=as.factor(babysex))

# Check for missing data
missing_data_summary=
  birthweight|>
  summarise_all(~ sum(is.na(.))) |>
  gather(key = "variable", value = "missing_count") |>
  filter(missing_count > 0)
print(missing_data_summary)
```
Based on the results from `Check for missing data`, there is no missing data in the remaining dataset of interest. 

#### My SLR Model
From my point of view, baby's birthweight involves considering various factors that may influence it including babyâ€™s length at birth and baby's head  circumference at birth. 
To explore my SLR model, let's first take a look at the distribution of birthweight with each of factor of interest. 
```{r}
birthweight |> 
  ggplot(aes(x=blength, y=bwt)) + 
  geom_point(alpha = .5)

birthweight |> 
  ggplot(aes(x=bhead, y=bwt)) + 
  geom_point(alpha = .5)
```

According to the scatterplots of the distribution above, we can see that there might be linear relationship between baby's birthweight with baby's length and baby's birthweight with baby's head  circumference. Therefore, my simple linear regression will be like this
```{r}
linear_own = lm(bwt ~ blength+bhead, data = birthweight)
```

#### Plot of Model Residuals against Fitted Values
```{r}
birthweight|> 
  add_predictions(linear_own) |> 
  add_residuals(linear_own)|>
  ggplot(aes(x = pred, y = resid) ) + geom_point(color="red")+
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals")
```

#### Two other models
```{r}
model2 <- lm(bwt ~ blength + gaweeks, data = birthweight)
model3 <- lm(bwt ~ bhead * blength * babysex, data = birthweight)
```

#### Cross Validation
```{r}
cv_df =
  crossv_mc(birthweight, 80) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df |> 
  mutate(
    linear_own  = map(train, \(df) lm(bwt ~ blength+bhead, data = df)),
    model2    = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model3  = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse_linear_own = map2_dbl(linear_own, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model2    = map2_dbl(model2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model3 = map2_dbl(model3, test, \(mod, df) rmse(model = mod, data = df)))
```

Finally, plot the prediction error distribution for each candidate model.
```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```